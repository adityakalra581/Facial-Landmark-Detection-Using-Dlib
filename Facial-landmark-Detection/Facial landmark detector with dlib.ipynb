{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five Point Facial Landmark detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project is done with proper guidance from Adrian RoseBrock article on his Blog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reference:\n",
    "https://www.pyimagesearch.com/2018/04/02/faster-facial-landmark-detector-with-dlib/?unapproved=678367&moderation-hash=9dca841018b6de5e88c7b492cb0082d2&submitted_comment=1#comment-678367\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are some changes done in order to make it compatible with windows and Jupyter Notebook.\n",
    "- I haven't used the argument parser method\n",
    "- Second, No cmd command is required.\n",
    "- shape_predictor_5_face_landmarks.dat : This file should be stored in the same folder as the notebook.(else provide the path)\n",
    "- Used vs.stream.release() for releasing the web cam as it was continuosly on.\n",
    "\n",
    "**Everything else was working perfectly fine.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n",
      "[INFO] camera sensor warming up...\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python faster_facial_landmarks.py --shape-predictor shape_predictor_5_face_landmarks.dat\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "# help=\"path to facial landmark predictor\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create the\n",
    "# facial landmark predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\n",
    "\n",
    "# initialize the video stream and sleep for a bit, allowing the\n",
    "# camera sensor to warm up\n",
    "print(\"[INFO] camera sensor warming up...\")\n",
    "\n",
    "\n",
    "\n",
    "#vs = VideoStream(src=1).start()\n",
    "vs = VideoStream(src=1).start()    # I have changed it for my webcam.\n",
    "\n",
    "\n",
    "# vs = VideoStream(usePiCamera=True).start() # Raspberry Pi\n",
    "time.sleep(2.0)\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "\t# detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\t# check to see if a face was detected, and if so, draw the total\n",
    "\t# number of faces on the frame\n",
    "    if len(rects) > 0:\n",
    "        text = \"{} face(s) found\".format(len(rects))\n",
    "        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "\n",
    "\t# loop over the face detections\n",
    "    for rect in rects:\n",
    "\t\t# compute the bounding box of the face and draw it on the\n",
    "\t\t# frame\n",
    "        (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH),(0, 255, 0), 1)\n",
    "\n",
    "\t\t# determine the facial landmarks for the face region, then\n",
    "\t\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "\t\t# array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    " \n",
    "\t\t# loop over the (x, y)-coordinates for the facial landmarks\n",
    "\t\t# and draw each of them\n",
    "        for (i, (x, y)) in enumerate(shape):\n",
    "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "\t# show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "#This will stop the streaming.\n",
    "vs.stream.release()  \n",
    "# To release the camera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five point facial Landmark detector on an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n",
      "[INFO] camera sensor warming up...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USAGE\n",
    "# python faster_facial_landmarks.py --shape-predictor shape_predictor_5_face_landmarks.dat\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "# help=\"path to facial landmark predictor\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create the\n",
    "# facial landmark predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\n",
    "\n",
    "# initialize the video stream and sleep for a bit, allowing the\n",
    "# camera sensor to warm up\n",
    "print(\"[INFO] camera sensor warming up...\")\n",
    "\n",
    "\n",
    "\n",
    "#vs = VideoStream(src=1).start()\n",
    "#vs = VideoStream(src=1).start()    # I have changed it for my webcam.\n",
    "\n",
    "\n",
    "# vs = VideoStream(usePiCamera=True).start() # Raspberry Pi\n",
    "#time.sleep(2.0)\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "img = cv2.imread(\"ady1.jpeg\")\n",
    "img = imutils.resize(img, width=400)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "\t# detect faces in the grayscale frame\n",
    "rects = detector(gray, 0)\n",
    "\n",
    "\t# check to see if a face was detected, and if so, draw the total\n",
    "\t# number of faces on the frame\n",
    "if len(rects) > 0:\n",
    "    text = \"{} face(s) found\".format(len(rects))\n",
    "    cv2.putText(img, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "\n",
    "\t# loop over the face detections\n",
    "for rect in rects:\n",
    "\t\t# compute the bounding box of the face and draw it on the\n",
    "\t\t# frame\n",
    "    (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "    cv2.rectangle(img, (bX, bY), (bX + bW, bY + bH),(0, 255, 0), 1)\n",
    "\n",
    "\t\t# determine the facial landmarks for the face region, then\n",
    "\t\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "\t\t# array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    " \n",
    "\t\t# loop over the (x, y)-coordinates for the facial landmarks\n",
    "\t\t# and draw each of them\n",
    "    for (i, (x, y)) in enumerate(shape):\n",
    "        cv2.circle(img, (x, y), 3, (150, 50, 200), -1)\n",
    "        cv2.putText(img, str(i + 1), (x - 10, y - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "\t# show the frame\n",
    "#cv2.imshow(\"a\", img)\n",
    "cv2.imwrite(\"a4.jpg\", img)\n",
    "#key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "#if key == ord(\"q\"):\n",
    "#    break\n",
    "\n",
    "# do a bit of cleanup\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "#vs.stop()\n",
    "#This will stop the streaming.\n",
    "#vs.stream.release()  \n",
    "# To release the camera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](face.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five Point Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ady1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68 Point Face Landmark Detection\n",
    "\n",
    "- Credits: https://www.youtube.com/watch?v=MrRGVOhARYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Drawing a rectangle Box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "\n",
    "\n",
    "detector=dlib.get_frontal_face_detector()\n",
    "cap=cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        #print(face)\n",
    "        x1=face.left()\n",
    "        y1=face.top()\n",
    "        x2=face.right()\n",
    "        y2=face.bottom()\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "    \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Link: \n",
    "- For downloading the code:\n",
    "- https://github.com/AKSHAYUBHAT/TensorFace/blob/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 2, (13, 200, 255), -1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Do it on a Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "#cap = cv2.VideoCapture(1)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "img = cv2.imread('personal.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray)\n",
    "for face in faces:\n",
    "    x1 = face.left()\n",
    "    y1 = face.top()\n",
    "    x2 = face.right()\n",
    "    y2 = face.bottom()\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 200, 0), 2)\n",
    "\n",
    "    landmarks = predictor(gray, face)\n",
    "\n",
    "    for n in range(0, 68):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        cv2.circle(img, (x, y), 3, (13, 200, 255), -1)\n",
    "        #255 Red, 196 Green and 13 Blue.  Color Combination for yellow.\n",
    "\n",
    "cv2.imwrite(\"a15.jpg\", img)\n",
    "cv2.waitKey()\n",
    "    #key = cv2.waitKey(1)\n",
    "    #if key == 27:\n",
    "        #break\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ady1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detected Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a13.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](a15.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
